<!DOCTYPE html>
<html>

<head>
    <title>PoseNet - Camera Feed Demo</title>
    <style>
    .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        color: black;
    }
    .footer-text {
        max-width: 600px;
        text-align: center;
        margin: auto;
    }
    @media only screen and (max-width: 600px) {
      .footer-text, .dg {
        display: none;
      }
    }
    </style>
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <video id="video" playsinline style=" -moz-transform: scaleX(-1);
    -o-transform: scaleX(-1);
    -webkit-transform: scaleX(-1);
    transform: scaleX(-1);
    display: none;
    ">
    </video>
    <canvas id="context"></canvas>
    <div class="footer">
        <div class="footer-text">
            <p>
                PoseNet runs with either a <strong>single-pose</strong> or <strong>multi-pose</strong> detection algorithm. The single person pose detector is faster and more accurate but requires only one subject present in the image.
                <br>
                <br> The <strong>output stride</strong> and <strong>image scale factor</strong> have the largest effects on accuracy/speed. A <i>higher</i> output stride results in lower accuracy but higher speed. A <i>higher</i> image scale factor results in higher accuracy but lower speed.
            </p>
        </div>
    </div>
    <script >
        
        const videoWidth = 600;
        const videoHeight = 500;
        const video = document.getElementById('video');
        video.width = videoWidth;
        video.height = videoHeight;
        navigator.mediaDevices.getUserMedia({ video: true, audio: false })
        .then(function(stream) {
            video.srcObject = stream;
            video.play();
        })
        .catch(function(err) {
            console.log("An error occurred! " + err);
        });
        let canvas = document.getElementById("context"); // canvasFrame is the id of <canvas>
        let context = canvas.getContext("2d");

        // let output = document.getElementById("context");
        //let src = new cv.Mat(height, width, cv.CV_8UC4);
        //let dst = new cv.Mat(height, width, cv.CV_8UC1);
        const FPS = 30;
        context.drawImage(video, 0, 0, videoWidth, videoHeight);

        // function processVideo() {
        //     console.log("here");
        //     let begin = Date.now();
        //     canvas.width = videoWidth;
        //     canvas.height = videoHeight;
        //     context.drawImage(video, 0, 0, videoWidth, videoHeight);
        //     //src.data.set(context.getImageData(0, 0, width, height).data);
        //     //cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
        //     //cv.imshow("canvasOutput", dst); // canvasOutput is the id of another <canvas>;
        //     // schedule next one.
        //     let delay = 1000/FPS - (Date.now() - begin);
        //     setTimeout(processVideo, delay);
        // }
        // // schedule first one.
        // setTimeout(processVideo, 0);
    </script>
</body>

</html>